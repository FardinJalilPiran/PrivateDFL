{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports, seed, device\n",
    "# =========================\n",
    "import os, struct, random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "seed = 42\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Parameters\n",
    "# =========================\n",
    "DATASET       = \"UCIHAR\"   # \"MNIST\" | \"UCIHAR\" | \"ISOLET\"\n",
    "Dataset_Split = \"non-IID\"      # \"IID\"   | \"non-IID\"\n",
    "CLIENTS       = 100  # number of clients; for non-IID each client gets ≈2 classes (some 3 if needed).\n",
    "                     # If nClasses < 2*CLIENTS, class assignments will repeat across clients.\n",
    "EPSILON       = 0.5\n",
    "DELTA_Coef    = 1e-3       # δ = DELTA_Coef / N_client\n",
    "D             = 2000       # hypervector dimension\n",
    "ROUND         = 30         # number of communication round\n",
    "nClasses      = None       # auto-set from file unless you override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Data loader (.choir_dat)\n",
    "# =========================\n",
    "def read_choir_file(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        nFeatures = struct.unpack('i', f.read(4))[0]\n",
    "        nClasses_ = struct.unpack('i', f.read(4))[0]\n",
    "        X, y = [], []\n",
    "        while True:\n",
    "            try:\n",
    "                vec = [struct.unpack('f', f.read(4))[0] for _ in range(nFeatures)]\n",
    "                lab = struct.unpack('i', f.read(4))[0]\n",
    "                X.append(vec); y.append(lab)\n",
    "            except Exception:\n",
    "                break\n",
    "    return nFeatures, nClasses_, np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCIHAR loaded. Train (7352, 561), Test (2947, 561), Classes 6\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Load + normalize\n",
    "# =========================\n",
    "train_path = os.path.join(\"Dataset\", f\"{DATASET}_train.choir_dat\")\n",
    "test_path  = os.path.join(\"Dataset\", f\"{DATASET}_test.choir_dat\")\n",
    "nF1, nC1, X_train, y_train = read_choir_file(train_path)\n",
    "nF2, nC2, X_test,  y_test  = read_choir_file(test_path)\n",
    "assert nF1 == nF2 and nC1 == nC2, \"Feature or class count mismatch train/test\"\n",
    "\n",
    "# L2 normalize (fit on train)\n",
    "norm = Normalizer(norm=\"l2\")\n",
    "X_train = norm.fit_transform(X_train)\n",
    "X_test  = norm.transform(X_test)\n",
    "\n",
    "# Set nClasses if not provided\n",
    "if nClasses is None:\n",
    "    nClasses = int(nC1)\n",
    "\n",
    "print(f\"{DATASET} loaded. Train {X_train.shape}, Test {X_test.shape}, Classes {nClasses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Split to clients (IID or non-IID)\n",
    "# =========================\n",
    "all_traindata = {}\n",
    "\n",
    "if Dataset_Split == \"IID\":\n",
    "    idx = np.arange(len(X_train))\n",
    "    np.random.shuffle(idx)  # random but still IID\n",
    "    Xs = X_train[idx]; ys = y_train[idx]\n",
    "    per = len(Xs) // CLIENTS\n",
    "    for k in range(CLIENTS):\n",
    "        s, e = k*per, (k+1)*per\n",
    "        all_traindata[str(k+1)] = {\"traindata\": Xs[s:e], \"trainlabels\": ys[s:e]}\n",
    "\n",
    "elif Dataset_Split == \"non-IID\":\n",
    "    # Each client gets ~2 classes (some may get 3 if needed)\n",
    "    classes = np.arange(nClasses)\n",
    "    np.random.shuffle(classes)\n",
    "\n",
    "    # How many classes per client: start with 2 each\n",
    "    classes_per_client = [2] * CLIENTS\n",
    "    leftover = nClasses - 2 * CLIENTS\n",
    "    i = 0\n",
    "    while leftover > 0:\n",
    "        classes_per_client[i] += 1\n",
    "        leftover -= 1\n",
    "        i = (i + 1) % CLIENTS\n",
    "\n",
    "    # Assign distinct class IDs to clients (wrap around if CLIENTS > nClasses)\n",
    "    assigned = []\n",
    "    ptr = 0\n",
    "    for k in range(CLIENTS):\n",
    "        take = classes_per_client[k]\n",
    "        pick = []\n",
    "        for _ in range(take):\n",
    "            pick.append(classes[ptr % nClasses])\n",
    "            ptr += 1\n",
    "        assigned.append(pick)\n",
    "\n",
    "    # Collect indices for each class\n",
    "    class_to_idx = {c: np.where(y_train == c)[0] for c in range(nClasses)}\n",
    "    for c in class_to_idx:\n",
    "        np.random.shuffle(class_to_idx[c])\n",
    "\n",
    "    # Build client datasets: draw equal portions from each assigned class\n",
    "    per_client = len(X_train) // CLIENTS  # aim for balanced client sizes\n",
    "    for k in range(CLIENTS):\n",
    "        clist = assigned[k]\n",
    "        take_each = max(1, per_client // len(clist))\n",
    "        idxs = []\n",
    "        for c in clist:\n",
    "            pool = class_to_idx[c]\n",
    "            take = min(take_each, len(pool))\n",
    "            idxs.extend(pool[:take])\n",
    "            class_to_idx[c] = pool[take:]\n",
    "        idxs = np.array(idxs, dtype=int)\n",
    "        np.random.shuffle(idxs)\n",
    "        all_traindata[str(k+1)] = {\"traindata\": X_train[idxs], \"trainlabels\": y_train[idxs]}\n",
    "else:\n",
    "    raise ValueError(\"Dataset_Split must be 'IID' or 'non-IID'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comoute the diffenrtial privacy nosie for the first clients in the first round\n",
    "def Noise_first_round(chv,eps,D,len_data,DELTA_Coef):\n",
    "    \n",
    "    std_noise = np.sqrt(2*D*np.log((1.25*len_data)/DELTA_Coef))/eps\n",
    "    \n",
    "    class_noisy = torch.zeros(chv.shape, dtype=torch.float32).device()\n",
    "    for i_class in range(len(chv)):\n",
    "        class_noisy[i_class] = chv[i_class] + torch.normal(mean=0, std = std_noise, size=(D,)).device()\n",
    "\n",
    "    return class_noisy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# DP noise schedules (paper theorems)\n",
    "# =========================\n",
    "def Noise_first_round(chv, eps, Ddim, N_client, delta_coef):\n",
    "    # Theorem 2: Γ_1^1 ~ N(0, 2D/ε^2 * ln[1.25 N / δ0])\n",
    "    std = np.sqrt((2.0 * Ddim * np.log((1.25 * N_client) / delta_coef))) / eps\n",
    "    noise = torch.normal(0.0, std, size=chv.shape, device=device)\n",
    "    return chv + noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pert_Noise(chv, eps, Ddim, rnd, K, k_idx):\n",
    "    # Theorem 5: Γ_k^r ~ N(0, 2D/ε^2 * ln[(K(r-1)+k)/(K(r-1)+k-1)])\n",
    "    num = (rnd - 1) * K + k_idx\n",
    "    den = (rnd - 1) * K + (k_idx - 1)\n",
    "    std = np.sqrt((2.0 * Ddim * np.log(num / den))) / eps\n",
    "    noise = torch.normal(0.0, std, size=chv.shape, device=device)\n",
    "    return chv + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# HD encode, train, update, infer\n",
    "# =========================\n",
    "def hd_encode(X, basis):\n",
    "    # X: [N, nFeatures], basis: [nFeatures, D] -> cos(X @ basis) -> [N, D]\n",
    "    return torch.cos(X @ basis)\n",
    "\n",
    "def Train_HD(data, labels, basis, nClasses_, Ddim, eps, clt_num, K, delta_coef):\n",
    "    # Build local class HVs, then add DP noise for round 1 at client clt_num\n",
    "    H = hd_encode(data, basis)  # [N, D]\n",
    "    class_hvs = torch.zeros((nClasses_, Ddim), dtype=torch.float32, device=device)\n",
    "    class_hvs.index_add_(0, labels, H)  # sum rows by class index\n",
    "\n",
    "    if clt_num == 1:\n",
    "        class_noisy = Noise_first_round(class_hvs, eps, Ddim, len(data), delta_coef)\n",
    "    else:\n",
    "        class_noisy = Pert_Noise(class_hvs, eps, Ddim, 1, K, clt_num)\n",
    "    return class_noisy\n",
    "\n",
    "def Update_HD(chv, data, labels, basis, eps, Ddim, rnd, K, clt_num):\n",
    "    # Perceptron-like correction with received secure model, then add Γ_k^r\n",
    "    H = hd_encode(data, basis)\n",
    "    order = list(range(len(data)))\n",
    "    random.shuffle(order)\n",
    "    for i in order:\n",
    "        guess = (chv @ H[i]).argmax()\n",
    "        if guess != labels[i]:\n",
    "            chv[labels[i]] += H[i]\n",
    "            chv[guess]      -= H[i]\n",
    "    chv = Pert_Noise(chv, eps, Ddim, rnd, K, clt_num)\n",
    "    return chv\n",
    "\n",
    "@torch.no_grad()\n",
    "def Infer(chv, Xte, yte, basis):\n",
    "    Xt  = torch.tensor(Xte, dtype=torch.float32, device=device)\n",
    "    yt  = torch.tensor(yte, dtype=torch.long,    device=device)\n",
    "    Ht  = hd_encode(Xt, basis)\n",
    "    pred = (Ht @ chv.T).argmax(dim=1)\n",
    "    return (pred == yt).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Round : 1/30, Test Accuracy: 41.84%\n",
      " Round : 10/30, Test Accuracy: 86.63%\n",
      " Round : 20/30, Test Accuracy: 88.26%\n",
      " Round : 30/30, Test Accuracy: 91.38%\n",
      " Final Round, Test Accuracy: 91.38%\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Build basis and run PrivateDFL\n",
    "# =========================\n",
    "nFeatures = X_train.shape[1]\n",
    "basis = torch.randn((nFeatures, D), dtype=torch.float32, device=device)\n",
    "class_hvs = torch.zeros((nClasses, D), dtype=torch.float32, device=device)\n",
    "\n",
    "# ---- Round 1: sequential clients build secure model\n",
    "for clt_num, client in enumerate(all_traindata, start=1):\n",
    "    train_data   = all_traindata[client]['traindata'].reshape(-1, nFeatures)\n",
    "    train_labels = all_traindata[client]['trainlabels']\n",
    "    Xc = torch.tensor(train_data,   dtype=torch.float32, device=device)\n",
    "    yc = torch.tensor(train_labels, dtype=torch.long,    device=device)\n",
    "    client_hvs = Train_HD(Xc, yc, basis, nClasses, D, EPSILON, clt_num, CLIENTS, DELTA_Coef)\n",
    "    class_hvs += client_hvs\n",
    "\n",
    "acc = Infer(class_hvs, X_test, y_test, basis)\n",
    "print(f\" Round : 1/{ROUND}, Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# ---- Rounds 2..R: each client updates in sequence (decentralized pass-through)\n",
    "for rnd in range(2, ROUND + 1):\n",
    "    for clt_num, client in enumerate(all_traindata, start=1):\n",
    "        train_data   = all_traindata[client]['traindata'].reshape(-1, nFeatures)\n",
    "        train_labels = all_traindata[client]['trainlabels']\n",
    "        Xc = torch.tensor(train_data,   dtype=torch.float32, device=device)\n",
    "        yc = torch.tensor(train_labels, dtype=torch.long,    device=device)\n",
    "        class_hvs = Update_HD(class_hvs, Xc, yc, basis, EPSILON, D, rnd, CLIENTS, clt_num)\n",
    "    acc = Infer(class_hvs, X_test, y_test, basis)\n",
    "    if rnd%10==0:\n",
    "        print(f\" Round : {rnd}/{ROUND}, Test Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "print(f\" Final Round, Test Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
